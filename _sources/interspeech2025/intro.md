# Interspeech 2025

We provide four notebooks, exemplifying the interpretability techniques we cover in the tutorial. The notebooks are designed to work on Google Colab, open them through the links below:

## Part I: Representation Understanding
- [Probing exercise: Does Wav2Vec2 encode vocal tract movements?](https://colab.research.google.com/github/interpretingdl/speech-interpretability-tutorial/blob/main/book/interspeech2025/representational-analyses/probing.ipynb)
- [Representation space comparisons: Locating acoustic and articulatory information in Wav2Vec2 with CKA](https://colab.research.google.com/github/interpretingdl/speech-interpretability-tutorial/blob/main/book/interspeech2025/representational-analyses/representation_space_comparisons.ipynb)

## Part II: Feature Importance Scoring
- [Context Mixing: Quantifying Context-Mixing in Speech Transformers](https://colab.research.google.com/github/interpretingdl/speech-interpretability-tutorial/blob/main/book/interspeech2025/feature-importance-scoring/context_mixing.ipynb)
- [Feature attribution: Explaining Speech Classification Models with Feature Attribution](https://colab.research.google.com/github/interpretingdl/speech-interpretability-tutorial/blob/main/book/interspeech2025/feature-importance-scoring/feature_attribution.ipynb)